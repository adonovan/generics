// A generic concurrency-safe cache that memoizes a function.
package main

import (
	"fmt"
	"sync"
	"time"
)

// TODO:
// - make error result of f optional somehow.
// - add option to suppress caching errors.
// - support cancellation

// A future.Cache is a concurrency safe memoization of a function f such
// that the value f(k) for each distinct key is computed at most once.
//
// TODO: if we used the generic hash map we could drop the 'comparable' constraint
// and let the user specify it.
type Cache[K comparable, V any] struct {
	mu sync.Mutex
	m  map[K]*future[V]
	f  func(K) (V, error)
}

// New returns a new Cache that memoizes calls to f.
// f must be concurrency safe.
func New[K comparable, V any](f func(K) (V, error)) *Cache[K, V] {
	return &Cache[K, V]{
		m: make(map[K]*future[V]),
		f: f,
	}
}

type future[V any] struct {
	done  chan struct{}
	value V
	err   error
}

// Get returns the value of f(k).
func (c *Cache[K, V]) Get(k K) (V, error) {
	c.mu.Lock()
	f, ok := c.m[k]
	if !ok {
		// first request: compute it
		f = &future[V]{done: make(chan struct{})}
		c.m[k] = f
		c.mu.Unlock()
		f.value, f.err = c.f(k)
		close(f.done)
	} else {
		// subsequent request: wait
		c.mu.Unlock()
		<-f.done
	}
	return f.value, f.err
}

func main() {
	t0 := time.Now()
	done := make(chan struct{})
	cache := New[string, int](slowStrlen)
	go func() {
		fmt.Println(cache.Get("hello"))
		fmt.Println(cache.Get("world"))
		close(done)
	}()
	fmt.Println(cache.Get("hello"))
	fmt.Println(cache.Get("world"))
	<-done
	fmt.Println(time.Since(t0)) // about 2s (not 4)
}

func slowStrlen(s string) (int, error) {
	time.Sleep(time.Second)
	return len(s), nil
}
